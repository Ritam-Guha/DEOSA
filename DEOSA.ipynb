{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Binary Equlibrium Optimizer with Simulated Annealing (version 1.2.1)\n",
    "## Last updated: 16/07/2020\n",
    "### Coders: Ritam Guha, Kushal Kanti Ghosh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math,time,sys\n",
    "import openpyxl as xl\n",
    "# from plot_graphs import plotter\n",
    "from datetime import datetime\n",
    "# from ipynb.fs.full.utilities import Ufunction, sign_func, onecount, reshape_np, compute_accuracy\n",
    "\n",
    "# for knapsack problem change fitness_FS to fitness_Knapsack\n",
    "# from ipynb.fs.full.utilities import fitness_Knapsack as fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ufunction(ip):\n",
    "    alpha = 2\n",
    "    beta = 1.5\n",
    "    op = alpha * pow(abs(ip), beta)\n",
    "    return op\n",
    "\n",
    "def Vfunction(ip):\n",
    "    op = 1 + ip*ip\n",
    "    op = math.sqrt(op)\n",
    "    op = ip/op\n",
    "    return abs(op)\n",
    "\n",
    "def sigmoid(ip):     \n",
    "    if ip < 0:\n",
    "        return 1 - 1/(1 + math.exp(ip))\n",
    "    else:\n",
    "        return 1/(1 + math.exp(-ip))\n",
    "\n",
    "\n",
    "def sign_func(x): \n",
    "    if x<0:\n",
    "        return -1\n",
    "    return 1\n",
    "\n",
    "def onecount(particle):\n",
    "    return int(np.sum(particle))\n",
    "\n",
    "def reshape_np(particle):\n",
    "    return np.reshape(particle, (1, particle.shape[0]))\n",
    "\n",
    "def compute_accuracy(train_X, train_Y, test_X, test_Y, particle):    \n",
    "    cols=np.flatnonzero(particle)     \n",
    "    if(cols.shape[0]==0):\n",
    "        return 0    \n",
    "    clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    train_data=train_X[:,cols]\n",
    "    test_data=test_X[:,cols]\n",
    "    clf.fit(train_data,train_Y)\n",
    "    val=clf.score(test_data,test_Y)\n",
    "    return val\n",
    "\n",
    "def fitness_FS(particles):\n",
    "    \n",
    "    # fitness computation\n",
    "    if(particles.ndim == 1):\n",
    "        particles = reshape_np(particles)\n",
    "        \n",
    "    [num_particles, dimension] = particles.shape\n",
    "    values = np.zeros((1, num_particles))\n",
    "    count = 0\n",
    "    \n",
    "    for particle in particles:  \n",
    "        current_particle = reshape_np(particle)\n",
    "        set_cnt=int(np.sum(current_particle))\n",
    "        \n",
    "        if(set_cnt == 0):\n",
    "            val = np.float64(1.0)     \n",
    "            \n",
    "        else:            \n",
    "            set_cnt=set_cnt/dimension\n",
    "            err = 1- compute_accuracy(train_X, train_Y, test_X, test_Y, particle)            \n",
    "            val = omega*err + (1-omega)*set_cnt\n",
    "        values[0, count] = np.float64(val) \n",
    "        count += 1            \n",
    "    return values\n",
    "\n",
    "\n",
    "def fitness_Knapsack(particles):\n",
    "     # fitness computation\n",
    "    if(particles.ndim == 1):\n",
    "        particles = reshape_np(particles)\n",
    "        \n",
    "    [num_particles, dimension] = particles.shape\n",
    "    values = np.zeros((1, num_particles))\n",
    "    count = 0\n",
    "    \n",
    "    for particle in particles:  \n",
    "        current_particle = reshape_np(particle)\n",
    "        set_cnt=int(np.sum(current_particle))\n",
    "        \n",
    "        if(set_cnt == 0):\n",
    "            val = np.float64(1.0)     \n",
    "            \n",
    "        else:            \n",
    "            pos = np.flatnonzero(particle)                \n",
    "            val = (np.sum(weights[pos])<=max_weight) * np.sum(worth[pos])\n",
    "        values[0, count] = -np.float64(val) \n",
    "        count += 1            \n",
    "    return values\n",
    "\n",
    "\n",
    "def avg_concentration(eq_pool, pool_size, dimension):    \n",
    "    avg = np.sum(eq_pool[0:pool_size,:], axis=0)         \n",
    "    avg = avg/pool_size\n",
    "    return avg\n",
    "\n",
    "\n",
    "def neighbor(particle, percent=0.3):   \n",
    "    current_particle = particle.copy()    \n",
    "    dimension = current_particle.shape[1]\n",
    "    num_change = int(dimension*percent)\n",
    "    pos = np.random.randint(0,dimension-1,num_change)\n",
    "    current_particle[0, pos] = 1 - current_particle[0, pos]\n",
    "    return current_particle    \n",
    "\n",
    "def initialize(partCount,dimension):\n",
    "    population=np.zeros((partCount,dimension))\n",
    "    minn = 1\n",
    "    maxx = math.floor(0.5*dimension)\n",
    "    if maxx<minn:\n",
    "        maxx = minn + 1\n",
    "\n",
    "    for i in range(partCount):\n",
    "        random.seed(i**3 + 10 + time.time() ) \n",
    "        no = random.randint(minn,maxx)\n",
    "        if no == 0:\n",
    "            no = 1\n",
    "        random.seed(time.time()+ 100)\n",
    "        pos = random.sample(range(0,dimension-1),no)\n",
    "        for j in pos:\n",
    "            population[i][j]=1\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SA(population, fitness_list):\n",
    "    \n",
    "    # simulated annealing\n",
    "    [particle_count, dimension] = np.shape(population)\n",
    "    T0 = dimension\n",
    "\n",
    "    for particle_no in range(particle_count):\n",
    "        T=2*dimension\n",
    "        current_particle = reshape_np(population[particle_no].copy())  \n",
    "        current_fitness = fitness(current_particle) \n",
    "        best_particle = current_particle.copy()\n",
    "        best_fitness = current_fitness.copy()        \n",
    "        \n",
    "        while T>T0:\n",
    "            new_particle = neighbor(current_particle)\n",
    "            new_fitness = np.float64(fitness(new_particle))            \n",
    "            \n",
    "            if new_fitness<best_fitness:\n",
    "                current_particle=new_particle.copy()\n",
    "                current_fitness=new_fitness.copy()\n",
    "                best_particle=current_particle.copy()\n",
    "                best_fitness=current_fitness.copy()\n",
    "                \n",
    "            elif new_fitness==best_fitness:\n",
    "                if onecount(new_particle)<onecount(best_particle):\n",
    "                    current_particle=new_particle.copy()\n",
    "                    current_fitness=new_fitness.copy()\n",
    "                    best_particle=current_particle.copy()\n",
    "                    best_fitness=current_fitness.copy()\n",
    "            else:            \n",
    "                prob=np.exp((best_fitness-current_fitness)/T)\n",
    "                if(random.random()<=prob):\n",
    "                    current_particle=new_particle.copy()\n",
    "                current_fitness=new_fitness\n",
    "            T=int(T*0.7)                \n",
    "        \n",
    "        population[particle_no, :]=best_particle.copy() \n",
    "        fitness_list[0, particle_no]=best_fitness.copy()                   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EO_SA(init_population, dimension, pool_size=4, max_iter=50, particle_count=100, allow_SA=True):\n",
    "    \n",
    "    # pool initialization\n",
    "    population = init_population.copy()\n",
    "    eq_pool = np.zeros((pool_size+1, dimension))\n",
    "    eq_fit = np.zeros((1, pool_size))\n",
    "    eq_fit[0, :] = 100\n",
    "    conv_plot = []\n",
    "        \n",
    "    # iterations start\n",
    "    for iter in range(max_iter):        \n",
    "        pop_new = np.zeros((particle_count, dimension))        \n",
    "        fitness_list = fitness(population) \n",
    "        sorted_idx = np.argsort(fitness_list)\n",
    "        population = population[sorted_idx, :].reshape((particle_count, dimension))\n",
    "        fitness_list = fitness_list[0, sorted_idx]\n",
    "\n",
    "        # replacements in the pool\n",
    "        for i in range(particle_count):\n",
    "            for j in range(pool_size):                 \n",
    "                if fitness_list[0, i] <= eq_fit[0, j]:\n",
    "                    eq_fit[0, j] = fitness_list[0, i].copy()\n",
    "                    eq_pool[j, :] = population[i, :].copy()\n",
    "                    break\n",
    "        \n",
    "\n",
    "        conv_plot.append(eq_fit[0, 0])\n",
    "        best_particle = eq_pool[0,:]\n",
    "                \n",
    "        Cave = avg_concentration(eq_pool,pool_size,dimension)\n",
    "        eq_pool[pool_size] = Cave.copy()\n",
    "\n",
    "        t = (1 - (iter/max_iter))**(a2*iter/max_iter)\n",
    "        \n",
    "        for i in range(particle_count):\n",
    "            \n",
    "            # randomly choose one candidate from the equillibrium pool\n",
    "            random.seed(time.time() + 100 + 0.02*i)\n",
    "            inx = random.randint(0,pool_size)\n",
    "            Ceq = np.array(eq_pool[inx])\n",
    "\n",
    "            lambda_vec = np.zeros(np.shape(Ceq))\n",
    "            r_vec = np.zeros(np.shape(Ceq))\n",
    "            for j in range(dimension):\n",
    "                random.seed(time.time() + 1.1)\n",
    "                lambda_vec[j] = random.random()\n",
    "                random.seed(time.time() + 10.01)\n",
    "                r_vec[j] = random.random()\n",
    "\n",
    "            F_vec = np.zeros(np.shape(Ceq))\n",
    "            for j in range(dimension):\n",
    "                x = -1*lambda_vec[j]*t \n",
    "                x = math.exp(x) - 1\n",
    "                x = a1 * sign_func(r_vec[j] - 0.5) * x\n",
    "\n",
    "            random.seed(time.time() + 200)\n",
    "            r1 = random.random()\n",
    "            random.seed(time.time() + 20)\n",
    "            r2 = random.random()\n",
    "            if r2 < GP:\n",
    "                GCP = 0\n",
    "            else:\n",
    "                GCP = 0.5 * r1\n",
    "            G0 = np.zeros(np.shape(Ceq))\n",
    "            G = np.zeros(np.shape(Ceq))\n",
    "            for j in range(dimension):\n",
    "                G0[j] = GCP * (Ceq[j] - lambda_vec[j]*population[i][j])\n",
    "                G[j] = G0[j]*F_vec[j]\n",
    "            \n",
    "            # use transfer function to map continuous->binary\n",
    "            for j in range(dimension):\n",
    "                temp = Ceq[j] + (population[i][j] - Ceq[j])*F_vec[j] + G[j]*(1 - F_vec[j])/lambda_vec[j]                \n",
    "                temp = Vfunction(temp)                \n",
    "                if temp>np.random.random():\n",
    "                    pop_new[i][j] = 1 - population[i][j]\n",
    "                else:\n",
    "                    pop_new[i][j] = population[i][j]                \n",
    "        \n",
    "        # performing simulated annealing\n",
    "        if(allow_SA):            \n",
    "            SA(pop_new, fitness_list)\n",
    "    \n",
    "            \n",
    "        population = pop_new.copy()        \n",
    "    \n",
    "        \n",
    "        \n",
    "    return best_particle, conv_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# datasets=[\"BreastCancer\",\"BreastEW\",\"CongressEW\",\"Exactly\",\"Exactly2\",\"HeartEW\",\"Ionosphere\",\"KrVsKpEW\",\"Lymphography\",\"M-of-n\",\"PenglungEW\",\"Sonar\",\"SpectEW\",\"Tic-tac-toe\",\"Vote\",\"WaveformEW\",\"Wine\",\"Zoo\"]\n",
    "def BEO_driver(dataset):\n",
    "\n",
    "    # initializing components\n",
    "    conv_plot_all = {}\n",
    "    conv_plot = {}\n",
    "    best_pop = -1\n",
    "    best_iter = -1\n",
    "    best_accuracy = -1\n",
    "    best_no_features = -1      \n",
    "\n",
    "    whole_accuracy = compute_accuracy(train_X, train_Y, test_X, test_Y, np.ones(dimension))\n",
    "    print(\"Total Acc: \",whole_accuracy * 100)     \n",
    "\n",
    "    # dictionary to store the final results\n",
    "    final_result ={}    \n",
    "\n",
    "    for particle_count in particle_count_testing:                \n",
    "\n",
    "        for max_iter in max_iter_testing:            \n",
    "            print(\"Particle count:\", particle_count)\n",
    "            print(\"Max iter:\", max_iter)            \n",
    "            \n",
    "            accuracy_BEO = 0\n",
    "            accuracy_BEOSA = 0\n",
    "            best_accuracy_BEO = 0\n",
    "            best_accuracy_BEOSA = 0\n",
    "\n",
    "            num_features_BEO = 0\n",
    "            num_features_BEOSA = 0   \n",
    "            best_num_features_BEO = 0\n",
    "            best_num_features_BEOSA = 0\n",
    "\n",
    "            BEO_key = dataset + \"_BEO\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)\n",
    "            BEOSA_key = dataset + \"_BEOSA\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)      \n",
    "\n",
    "            for run in range(max_runs):\n",
    "                \n",
    "                print(\"Run\", run)\n",
    "                \n",
    "                population = initialize(particle_count, dimension) \n",
    "                print(\"BEO starts...\")\n",
    "                best_particle_BEO, conv_BEO = EO_SA(init_population=population.copy(), pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, dimension=dimension, allow_SA=False)            \n",
    "                \n",
    "                print(\"BEOSA starts...\")\n",
    "                best_particle_BEOSA, conv_BEOSA = EO_SA(init_population=population.copy(), pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, dimension=dimension, allow_SA=True)                                                    \n",
    "\n",
    "                conv_plot_all[\"BEO_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)] = conv_BEO\n",
    "                conv_plot_all[\"BEOSA_pop_\" + str(particle_count)+ \"_iter_\" + str(max_iter)] = conv_BEOSA                        \n",
    "\n",
    "                accuracy_BEO = compute_accuracy(train_X, train_Y, test_X, test_Y, best_particle_BEO) * 100\n",
    "                accuracy_BEOSA = compute_accuracy(train_X, train_Y, test_X, test_Y, best_particle_BEOSA) * 100\n",
    "\n",
    "                num_features_BEO = onecount(best_particle_BEO)\n",
    "                num_features_BEOSA = onecount(best_particle_BEOSA)\n",
    "                \n",
    "                if(accuracy_BEO > best_accuracy_BEO):\n",
    "                    best_accuracy_BEO = accuracy_BEO.copy()\n",
    "                    best_num_features_BEO = np.float64(num_features_BEO).copy()\n",
    "                    \n",
    "                if(accuracy_BEOSA > best_accuracy_BEOSA):\n",
    "                    best_accuracy_BEOSA = accuracy_BEOSA.copy()\n",
    "                    best_num_features_BEOSA = np.float64(num_features_BEOSA).copy()\n",
    "\n",
    "           \n",
    "            if(best_accuracy_BEOSA > best_accuracy):\n",
    "                best_pop = particle_count\n",
    "                best_iter = max_iter                \n",
    "\n",
    "            final_result[BEO_key + \"_accuracy\"] = best_accuracy_BEO\n",
    "            final_result[BEOSA_key + \"_accuracy\"] = best_accuracy_BEOSA\n",
    "\n",
    "            final_result[BEO_key + \"_num_features\"] = best_num_features_BEO\n",
    "            final_result[BEOSA_key + \"_num_features\"] = best_num_features_BEOSA\n",
    "\n",
    "            print('BEO:', best_accuracy_BEO)\n",
    "            print('BEOSA:', best_accuracy_BEOSA)          \n",
    "\n",
    "\n",
    "    print(\"Best combination:\" + \" Pop-\" + str(best_pop) + \" Iter-\" + str(best_iter))\n",
    "    conv_plot[\"BEO\"] = conv_plot_all[\"BEO_pop_\" + str(best_pop) + \"_iter_\" + str(max_iter)]\n",
    "    conv_plot[\"BEOSA\"] = conv_plot_all[\"BEOSA_pop_\" + str(best_pop) + \"_iter_\" + str(max_iter)]\n",
    "        \n",
    "    return final_result, conv_plot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plottings \n",
    "def plot_graph(final_result, conv_plot, dataset):\n",
    "\n",
    "    processes = ['BEO', 'BEOSA']   \n",
    "\n",
    "    ################# plotting parameter-variation graphs ##################\n",
    "    accuracy_var_pop_BEO = []\n",
    "    accuracy_var_pop_BEOSA = []\n",
    "\n",
    "\n",
    "    for particle_count in particle_count_testing:\n",
    "        for max_iter in max_iter_testing:\n",
    "            BEO_key = dataset + \"_BEO\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter) + \"_runs_\" + str(max_runs)\n",
    "            BEOSA_key = dataset + \"_BEOSA\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter) + \"_runs_\" + str(max_runs)\n",
    "\n",
    "            accuracy_var_pop_BEO.append(final_result[BEO_key + \"_accuracy\"])\n",
    "            accuracy_var_pop_BEOSA.append(final_result[BEOSA_key + \"_accuracy\"])\n",
    "\n",
    "    process_dict = {'BEO':accuracy_var_pop_BEO, 'BEOSA':accuracy_var_pop_BEOSA}\n",
    "    output_file = dataset + \"_parameter_variation\" + \".png\"\n",
    "    plotter(dataset_name=dataset, x=particle_count_testing, x_label=\"Population size\", y_dict=process_dict, y_objects=processes, y_label=\"Accuracy\", title=dataset, storage_destination=\"Parameter Variation\", file_name=output_file)        \n",
    "    ###################################################################\n",
    "    \n",
    "    \n",
    "\n",
    "    ################# plotting convergence graphs #####################\n",
    "     \n",
    "    x_range = np.arange(0, max_iter, 1)\n",
    "\n",
    "    process_dict = {'BEO':conv_plot[\"BEO\"], 'BEOSA':conv_plot[\"BEOSA\"]}    \n",
    "    output_file = dataset + \"_convergence\" + \".png\"\n",
    "    plotter(dataset_name=dataset, x=x_range, x_label=\"#Iteration\", y_dict=process_dict, y_objects=processes, y_label=\"Fitness\", title=dataset, storage_destination=\"Convergence\", file_name=output_file)\n",
    "\n",
    "    ###################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_excel(final_result=\"\", dataset=\"\", save_type=\"parameter variation\", init=0):\n",
    "    # code to save the results in an excel file\n",
    "    \n",
    "    if(save_type == \"parameter variation\"):                \n",
    "        \n",
    "        if(init==1):     \n",
    "            wb = xl.Workbook()\n",
    "            ws = wb.active\n",
    "            wb.remove(ws)\n",
    "            for max_iter in max_iter_testing:            \n",
    "                ws = wb.create_sheet(\"Iter_\" + str(max_iter))\n",
    "                ws.title = \"Iter_\" + str(max_iter)\n",
    "                ws.merge_cells(start_row=1, start_column=1, end_row=3, end_column=1) \n",
    "                ws.cell(1,1).value = \"population size\"\n",
    "\n",
    "                cur_row = 4\n",
    "                cur_col = 1\n",
    "\n",
    "                for particle_count in particle_count_testing:\n",
    "                    ws.cell(cur_row, cur_col).value = particle_count\n",
    "                    cur_row += 1\n",
    "\n",
    "                \n",
    "        else:\n",
    "            wb = xl.load_workbook(\"Results/parameter_variation.xlsx\")\n",
    "            for max_iter in max_iter_testing:    \n",
    "                ws = wb[\"Iter_\" + str(max_iter)]\n",
    "                cur_row = 1\n",
    "                cur_col = ws.max_column + 1\n",
    "\n",
    "                # setting headers\n",
    "                ws.merge_cells(start_row=cur_row, start_column=cur_col, end_row=cur_row, end_column=cur_col+3) \n",
    "                ws.merge_cells(start_row=cur_row+1, start_column=cur_col, end_row=cur_row+1, end_column=cur_col+1)\n",
    "                ws.merge_cells(start_row=cur_row+1, start_column=cur_col+2, end_row=cur_row+1, end_column=cur_col+3)\n",
    "\n",
    "                ws.cell(cur_row, cur_col).value = dataset\n",
    "                ws.cell(cur_row+1, cur_col).value = \"BEO\"\n",
    "                ws.cell(cur_row+1, cur_col+2).value = \"BEOSA\"\n",
    "                ws.cell(cur_row+2, cur_col).value = \"Accuracy\"\n",
    "                ws.cell(cur_row+2, cur_col+1).value = \"#features\"\n",
    "                ws.cell(cur_row+2, cur_col+2).value = \"Accuracy\"\n",
    "                ws.cell(cur_row+2, cur_col+3).value = \"#features\"\n",
    "\n",
    "                cur_row += 3            \n",
    "                for particle_count in particle_count_testing:\n",
    "\n",
    "                    BEO_key = dataset + \"_BEO\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)\n",
    "                    BEOSA_key = dataset + \"_BEOSA\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)\n",
    "\n",
    "                    ws.cell(cur_row, cur_col).value = final_result[BEO_key+\"_accuracy\"]\n",
    "                    ws.cell(cur_row, cur_col+1).value = final_result[BEO_key+\"_num_features\"]\n",
    "                    ws.cell(cur_row, cur_col+2).value = final_result[BEOSA_key+\"_accuracy\"]\n",
    "                    ws.cell(cur_row, cur_col+3).value = final_result[BEOSA_key+\"_num_features\"]\n",
    "\n",
    "                    cur_row += 1\n",
    "                    \n",
    "        wb.save(\"Results/parameter_variation.xlsx\")   \n",
    "                    \n",
    "    elif(save_type == \"convergence\"):                \n",
    "\n",
    "        if(init==1):     \n",
    "            wb = xl.Workbook()\n",
    "            ws = wb.active\n",
    "            wb.remove(ws)\n",
    "            \n",
    "            for max_iter in max_iter_testing:            \n",
    "                ws = wb.create_sheet(\"Iter_\" + str(max_iter))\n",
    "                ws.title = \"Iter_\" + str(max_iter)\n",
    "\n",
    "                cur_row = 1\n",
    "                cur_col = 1\n",
    "                ws.merge_cells(start_row=cur_row, start_column=cur_col, end_row=cur_row+1, end_column=cur_col)\n",
    "                ws.cell(cur_row, cur_col).value = \"#Iteration\"\n",
    "\n",
    "                cur_row += 2\n",
    "\n",
    "                for count in range(1, max_iter+1):\n",
    "                    ws.cell(cur_row, cur_col).value = count\n",
    "                    cur_row += 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            wb = xl.load_workbook(\"Results/convergence.xlsx\")\n",
    "            for max_iter in max_iter_testing:    \n",
    "                ws = wb[\"Iter_\" + str(max_iter)]\n",
    "                cur_row = 1\n",
    "                cur_col = ws.max_column + 1\n",
    "\n",
    "                # setting headers\n",
    "                ws.merge_cells(start_row=cur_row, start_column=cur_col, end_row=cur_row, end_column=cur_col+1)                \n",
    "\n",
    "                ws.cell(cur_row, cur_col).value = dataset\n",
    "                ws.cell(cur_row+1, cur_col).value = \"BEO\"\n",
    "                ws.cell(cur_row+1, cur_col+1).value = \"BEOSA\"                \n",
    "\n",
    "                cur_row += 2            \n",
    "                for iteration_no in range(max_iter):\n",
    "\n",
    "                    conv_BEO = conv_plot[\"BEO\"]\n",
    "                    conv_BEOSA = conv_plot[\"BEOSA\"]\n",
    "\n",
    "                    ws.cell(cur_row, cur_col).value = conv_BEO[iteration_no]\n",
    "                    ws.cell(cur_row, cur_col+1).value = conv_BEOSA[iteration_no]                    \n",
    "\n",
    "                    cur_row += 1\n",
    "\n",
    "        wb.save(\"Results/convergence.xlsx\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the global parameters and run the following cell to perform feature selection over UCI datasets\n",
    "\n",
    "* This code will automatically create two excel files - one for parameter variation and another one for convergence. The results will be saved as parameter_variation and convergence in Results folder\n",
    "\n",
    "* It will also plot convergence curves which will be saved in Convergence folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: BreastCancer\n",
      "dimension: 10\n",
      "Total Acc:  57.85714285714286\n",
      "Particle count: 10\n",
      "Max iter: 10\n",
      "Run 0\n",
      "BEO starts...\n",
      "BEOSA starts...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-5a44b8e86a5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mfinal_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBEO_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mplot_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-89-0ad5b7ab4df5>\u001b[0m in \u001b[0;36mBEO_driver\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BEOSA starts...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                 \u001b[0mbest_particle_BEOSA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_BEOSA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEO_SA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_population\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparticle_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparticle_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_SA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mconv_plot_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BEO_pop_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparticle_count\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_iter_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_BEO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-88-bf6d2cbed307>\u001b[0m in \u001b[0;36mEO_SA\u001b[1;34m(init_population, dimension, pool_size, max_iter, particle_count, allow_SA)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;31m# performing simulated annealing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_SA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mSA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitness_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-f79a7cab8085>\u001b[0m in \u001b[0;36mSA\u001b[1;34m(population, fitness_list)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcurrent_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreshape_np\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparticle_no\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mcurrent_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_particle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mbest_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_particle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mbest_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_fitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-883c2a77634e>\u001b[0m in \u001b[0;36mfitness_FS\u001b[1;34m(particles)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mset_cnt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_cnt\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0momega\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0merr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0momega\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mset_cnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-883c2a77634e>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[1;34m(train_X, train_Y, test_X, test_Y, particle)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_k\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneigh_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneigh_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mmode\u001b[1;34m(a, axis, nan_policy)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mmodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mode1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m     \u001b[0mnewshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[0mnewshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m_mode1D\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_mode1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcnts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;31m# np.apply_along_axis will convert the _mode1D tuples to a numpy array, casting types in the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set the global parameters over here\n",
    "datasets=[\"BreastCancer\",\"BreastEW\",\"CongressEW\",\"Exactly\",\"Exactly2\",\"HeartEW\",\"Ionosphere\",\"KrVsKpEW\",\"Lymphography\",\"M-of-n\",\"PenglungEW\",\"Sonar\",\"SpectEW\",\"Tic-tac-toe\",\"Vote\",\"WaveformEW\",\"Wine\",\"Zoo\"]\n",
    "particle_count_testing = [10, 20]\n",
    "max_iter_testing = [10, 20]\n",
    "max_runs = 15\n",
    "omega = 0.9                 \n",
    "a2 = 1\n",
    "a1 = 2\n",
    "GP = 0.5\n",
    "pool_size = 4\n",
    "fitness = fitness_FS\n",
    "\n",
    "# initializing the excel files\n",
    "save_excel(init=1, save_type=\"parameter variation\")\n",
    "save_excel(init=1, save_type=\"convergence\")\n",
    "\n",
    "# start iterating over the datasets\n",
    "for dataset in datasets:\n",
    "    \n",
    "    # reading dataset\n",
    "    print(\"Dataset:\", dataset)\n",
    "    df=pd.read_csv(\"Data/\"+dataset+\".csv\")\n",
    "    (a,b)=np.shape(df)\n",
    "    data = df.values[:,0:b-1]\n",
    "    label = df.values[:,b-1]\n",
    "    dimension = np.shape(data)[1] #particle dimension   \n",
    "    print(\"dimension:\", dimension)\n",
    "\n",
    "    # loading_dataset\n",
    "    cross = 5\n",
    "    test_size = (1/cross)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(data, label,stratify=label ,test_size=test_size)\n",
    "     \n",
    "\n",
    "    final_result, conv_plot = BEO_driver(dataset)\n",
    "    plot_graph(final_result, conv_plot, dataset)\n",
    "\n",
    "    save_excel(final_result, dataset, save_type=\"parameter variation\")\n",
    "    save_excel(final_result, dataset, save_type=\"convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell for solving knapsack problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3610494.0 0.0 3924400.0 0.0\n",
      "3740776.0 0.0 3740776.0 0.0\n",
      "3347452.0 0.0 3347452.0 0.0\n",
      "4082475.0 0.0 4082475.0 0.0\n",
      "4856975.366666666 1355.0869709686126 4857227.0 0.0\n",
      "5685907.7 16044.021509895829 5688887.0 0.0\n",
      "6463514.0 0.0 6498597.0 0.0\n",
      "5169676.0 0.0 5169676.0 0.0\n",
      "6903672.0 0.0 6992404.0 0.0\n",
      "5227215.0 0.0 5227215.0 0.0\n",
      "7821255.0 0.0 7842384.5 11703.505138062985\n",
      "8881820.0 0.0 9341431.3 19418.632957634614\n",
      "8948033.866666667 81936.00056252578 9141289.3 14477.438371825316\n",
      "9126071.0 0.0 9326519.033333333 22462.72019218114\n",
      "7267954.0 0.0 7760444.8 8221.736395677011\n",
      "10558912.166666666 21681.380632673947 10659381.0 31178.235206630925\n",
      "9536420.7 27402.723153183157 9740663.0 33023.791986990225\n",
      "10257609.0 0.0 10624542.633333333 44763.86923586427\n",
      "8740236.966666667 7519.933605572739 8863593.933333334 31942.57243964897\n",
      "9300655.9 10148.63206989001 9309090.733333332 18480.356587348513\n",
      "13017232.633333333 17699.331415778266 13398986.3 50160.74151641567\n",
      "11997124.166666666 38797.60952694838 12075179.066666666 34645.942333779225\n",
      "10985210.133333333 41433.790755640766 12345731.0 31244.35425374212\n",
      "11151603.866666667 26073.359462272772 11715570.533333333 32635.66345450258\n",
      "13747503.566666666 48360.741854444525 13829445.6 52481.845349034746\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Data/Knapsack/'\n",
    "file_names = [\"ks_8a\", \"ks_8b\", \"ks_8c\", \"ks_8d\", \"ks_8e\", \"ks_12a\", \"ks_12b\", \"ks_12c\", \"ks_12d\", \"ks_12e\", \"ks_16a\", \"ks_16b\", \"ks_16c\", \"ks_16d\", \"ks_16e\", \"ks_20a\", \"ks_20b\", \"ks_20c\", \"ks_20d\", \"ks_20e\", \"ks_24a\", \"ks_24b\", \"ks_24c\", \"ks_24d\", \"ks_24e\"]\n",
    "\n",
    "# set the global parameters\n",
    "omega = 0.9                 \n",
    "a2 = 1\n",
    "a1 = 2\n",
    "GP = 0.5\n",
    "max_runs = 30\n",
    "particle_count = 20\n",
    "dimension = -1\n",
    "max_iter = 500\n",
    "pool_size = 30\n",
    "fitness = fitness_Knapsack\n",
    "\n",
    "weights = []\n",
    "worth = []\n",
    "max_weight = -1\n",
    "\n",
    "for file_name in file_names:    \n",
    "    fname = file_path + file_name + \".txt\"     \n",
    "    x = open(fname, 'r')\n",
    "    count = int(x.readline())\n",
    "    \n",
    "    weights = np.array(list(map(int, x.readline().split())))\n",
    "    worth = np.array(list(map(int, x.readline().split())))\n",
    "    max_weight = int(x.readline())\n",
    "\n",
    "    dimension = count\n",
    "    \n",
    "    population = initialize(particle_count, dimension)\n",
    "    fitness_list = fitness(population)\n",
    "\n",
    "    sorted_idx = np.argsort(fitness_list)\n",
    "    population = population[sorted_idx, :].reshape((particle_count, dimension))\n",
    "    fitness_list = fitness_list[0, sorted_idx]\n",
    "\n",
    "    best_particle_BEO = np.zeros((max_runs, dimension))\n",
    "    best_particle_BEOSA = np.zeros((max_runs, dimension))\n",
    "    \n",
    "    conv_BEO = np.zeros((max_runs, max_iter))\n",
    "    conv_BEOSA = np.zeros((max_runs, max_iter))\n",
    "    \n",
    "    best_fitness_BEO = np.zeros((1, max_runs))\n",
    "    best_fitness_BEOSA = np.zeros((1, max_runs))\n",
    "\n",
    "    for run_no in range(max_runs):    \n",
    "        best_particle_BEO[run_no,:], conv_BEO[run_no,:] = EO_SA(init_population=population, dimension=dimension, pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, allow_SA=False)\n",
    "        best_particle_BEOSA[run_no,:], conv_BEOSA[run_no,:] = EO_SA(init_population=population, dimension=dimension, pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, allow_SA=True)\n",
    "    \n",
    "    best_fitness_BEO[0, :] = fitness(best_particle_BEO)\n",
    "    best_fitness_BEOSA[0, :] = fitness(best_particle_BEOSA)\n",
    "    \n",
    "    print(-np.mean(best_fitness_BEO), np.std(best_fitness_BEO), -np.mean(best_fitness_BEOSA), np.std(best_fitness_BEOSA))\n",
    "    \n",
    "#     print(\"Dataset:%s  Mean:%f  Std:%f\" %(file_name, -np.mean(best_fitness), np.std(best_fitness)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
