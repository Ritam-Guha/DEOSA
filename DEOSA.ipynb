{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Binary Equlibrium Optimizer with Simulated Annealing (version 1.2.1)\n",
    "## Last updated: 16/07/2020\n",
    "### Coders: Ritam Guha, Kushal Kanti Ghosh\n"
   ]
  },
  {
   "source": [
    "### Import all the necessary libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from _utilities import compute_accuracy, initialize, save_excel, avg_concentration, sign_func, reshape_np, find_neighbor, onecount\n",
    "from _utilities import Ufunction as transfer_func\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "source": [
    "## Define the fitness function\n",
    "There are two types - \n",
    "* fitness_FS: for feature selection\n",
    "* fitness_Knapsack: for 0-1 knapsack"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_FS(particles):\n",
    "    # fitness computation for feature selection\n",
    "    if(particles.ndim == 1):\n",
    "        particles = reshape_np(particles)\n",
    "        \n",
    "    [num_particles, dimension] = particles.shape\n",
    "    values = np.zeros((1, num_particles))\n",
    "    count = 0\n",
    "    \n",
    "    for particle in particles:  \n",
    "        current_particle = reshape_np(particle)\n",
    "        set_cnt=int(np.sum(current_particle))\n",
    "        \n",
    "        if(set_cnt == 0):\n",
    "            val = np.float64(1.0)     \n",
    "            \n",
    "        else:            \n",
    "            set_cnt=set_cnt/dimension\n",
    "            err = 1- compute_accuracy(train_X, train_Y, test_X, test_Y, particle)            \n",
    "            val = omega*err + (1-omega)*set_cnt\n",
    "        values[0, count] = np.float64(val) \n",
    "        count += 1            \n",
    "    return values\n",
    "\n",
    "\n",
    "def fitness_Knapsack(particles):\n",
    "     # fitness computation for knapsack \n",
    "    if(particles.ndim == 1):\n",
    "        particles = reshape_np(particles)\n",
    "        \n",
    "    [num_particles, dimension] = particles.shape\n",
    "    values = np.zeros((1, num_particles))\n",
    "    count = 0\n",
    "    \n",
    "    for particle in particles:  \n",
    "        current_particle = reshape_np(particle)\n",
    "        set_cnt=int(np.sum(current_particle))\n",
    "        \n",
    "        if(set_cnt == 0):\n",
    "            val = np.float64(1.0)     \n",
    "            \n",
    "        else:            \n",
    "            pos = np.flatnonzero(particle)                \n",
    "            val = (np.sum(weights[pos])<=max_weight) * np.sum(worth[pos])\n",
    "        values[0, count] = -np.float64(val) \n",
    "        count += 1            \n",
    "    return values"
   ]
  },
  {
   "source": [
    "## Simulated Annealing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SA(population, fitness):\n",
    "    # simulated annealing\n",
    "    [particle_count, dimension] = population.shape\n",
    "    T0 = dimension\n",
    "\n",
    "    for particle_no in range(particle_count):\n",
    "        T = 2*dimension\n",
    "        current_particle = reshape_np(population[particle_no].copy())  \n",
    "        current_fitness = compute_fitness(current_particle) \n",
    "        best_particle = current_particle.copy()\n",
    "        best_fitness = current_fitness.copy()        \n",
    "        \n",
    "        while T>T0:\n",
    "            new_particle = find_neighbor(current_particle)\n",
    "            new_fitness = np.float64(compute_fitness(new_particle))            \n",
    "            \n",
    "            if new_fitness < best_fitness:\n",
    "                current_particle = new_particle.copy()\n",
    "                current_fitness = new_fitness.copy()\n",
    "                best_particle = current_particle.copy()\n",
    "                best_fitness = current_fitness.copy()\n",
    "    \n",
    "            else:            \n",
    "                prob = np.exp((best_fitness-current_fitness)/T)\n",
    "                if(np.random.random() <= prob):\n",
    "                    current_particle = new_particle.copy()\n",
    "                current_fitness = new_fitness\n",
    "                \n",
    "            T = int(T*0.7)                \n",
    "        \n",
    "        population[particle_no, :] = best_particle.copy() \n",
    "        fitness[0, particle_no] = best_fitness.copy()                   \n",
    "        "
   ]
  },
  {
   "source": [
    "## DEO with SA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEO_SA(init_population, dimension, pool_size=4, max_iter=50, particle_count=100, allow_SA=True):\n",
    "    # pool initialization\n",
    "    population = init_population.copy()\n",
    "    eq_pool = np.zeros((pool_size+1, dimension))\n",
    "    eq_fit = np.zeros((1, pool_size))\n",
    "    eq_fit[0, :] = 100\n",
    "    conv_plot = []\n",
    "        \n",
    "    # iterations start\n",
    "    for iter in range(max_iter):        \n",
    "        pop_new = np.zeros((particle_count, dimension))        \n",
    "        fitness_list = compute_fitness(population) \n",
    "        sorted_idx = np.argsort(fitness_list)\n",
    "        population = population[sorted_idx, :].reshape((particle_count, dimension))\n",
    "        fitness_list = fitness_list[0, sorted_idx]\n",
    "\n",
    "        # replacements in the pool\n",
    "        for i in range(particle_count):\n",
    "            for j in range(pool_size):                 \n",
    "                if fitness_list[0, i] <= eq_fit[0, j]:\n",
    "                    eq_fit[0, j] = fitness_list[0, i].copy()\n",
    "                    eq_pool[j, :] = population[i, :].copy()\n",
    "                    break\n",
    "        \n",
    "\n",
    "        conv_plot.append(eq_fit[0, 0])\n",
    "        best_particle = eq_pool[0,:]\n",
    "                \n",
    "        Cave = avg_concentration(eq_pool,pool_size,dimension)\n",
    "        eq_pool[pool_size] = Cave.copy()\n",
    "\n",
    "        t = (1 - (iter/max_iter))**(a2*iter/max_iter)\n",
    "        \n",
    "        for i in range(particle_count): \n",
    "            # randomly choose one candidate from the equillibrium pool\n",
    "            inx = np.random.randint(0,pool_size)\n",
    "            Ceq = np.array(eq_pool[inx])\n",
    "\n",
    "            lambda_vec = np.zeros(np.shape(Ceq))\n",
    "            r_vec = np.zeros(np.shape(Ceq))\n",
    "            for j in range(dimension):\n",
    "                lambda_vec[j], r_vec[j] = np.random.random(2)\n",
    "\n",
    "            F_vec = np.zeros(np.shape(Ceq))\n",
    "            for j in range(dimension):\n",
    "                x = -1*lambda_vec[j]*t \n",
    "                x = np.exp(x) - 1\n",
    "                x = a1 * sign_func(r_vec[j] - 0.5) * x\n",
    "\n",
    "            r1, r2 = np.random.random(2)\n",
    "    \n",
    "            if r2 < GP:\n",
    "                GCP = 0\n",
    "            else:\n",
    "                GCP = 0.5 * r1\n",
    "\n",
    "            G0 = np.zeros(np.shape(Ceq))\n",
    "            G = np.zeros(np.shape(Ceq))\n",
    "\n",
    "            for j in range(dimension):\n",
    "                G0[j] = GCP * (Ceq[j] - lambda_vec[j]*population[i][j])\n",
    "                G[j] = G0[j]*F_vec[j]\n",
    "            \n",
    "            # use transfer function to map continuous->binary\n",
    "            for j in range(dimension):\n",
    "                temp = Ceq[j] + (population[i][j] - Ceq[j])*F_vec[j] + G[j]*(1 - F_vec[j])/lambda_vec[j]                \n",
    "                temp = transfer_func(temp)                \n",
    "                if temp>np.random.random():\n",
    "                    pop_new[i][j] = 1 - population[i][j]\n",
    "                else:\n",
    "                    pop_new[i][j] = population[i][j]                \n",
    "        \n",
    "        # performing simulated annealing\n",
    "        if(allow_SA):            \n",
    "            SA(pop_new, fitness_list)\n",
    "    \n",
    "            \n",
    "        population = pop_new.copy()        \n",
    "        \n",
    "    return best_particle, conv_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEO_driver(dataset):\n",
    "    # initializing components\n",
    "    conv_plot_all = {}\n",
    "    conv_plot = {}\n",
    "    best_pop = -1\n",
    "    best_iter = -1\n",
    "    best_accuracy = -1\n",
    "    best_no_features = -1      \n",
    "\n",
    "    whole_accuracy = compute_accuracy(train_X, train_Y, test_X, test_Y, np.ones(dimension))\n",
    "    print(\"Total Acc: \",whole_accuracy * 100)     \n",
    "\n",
    "    # dictionary to store the final results\n",
    "    final_result ={}    \n",
    "\n",
    "    for particle_count in particle_count_testing:                \n",
    "        for max_iter in max_iter_testing:     \n",
    "            \n",
    "            print(\"Particle count:\", particle_count)\n",
    "            print(\"Max iter:\", max_iter)            \n",
    "            \n",
    "            accuracy_DEO = 0\n",
    "            accuracy_DEOSA = 0\n",
    "            best_accuracy_DEO = 0\n",
    "            best_accuracy_DEOSA = 0\n",
    "            avg_accuracy_DEO = 0\n",
    "            avg_accuracy_DEOSA = 0\n",
    "            accuracy_DEO_runs = []\n",
    "            accuracy_DEOSA_runs = []\n",
    "\n",
    "            num_features_DEO = 0\n",
    "            num_features_DEOSA = 0   \n",
    "            best_num_features_DEO = 0\n",
    "            best_num_features_DEOSA = 0\n",
    "            avg_num_features_DEO = 0\n",
    "            avg_num_features_DEOSA = 0\n",
    "            num_features_DEO_runs = []\n",
    "            num_features_DEOSA_runs = []\n",
    "\n",
    "            DEO_key = dataset + \"_DEO\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)\n",
    "            DEOSA_key = dataset + \"_DEOSA\" + \"_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)      \n",
    "\n",
    "            for run in range(max_runs):\n",
    "                \n",
    "                # print(\"Run \", run+1)\n",
    "                \n",
    "                population = initialize(particle_count, dimension) \n",
    "                # print(\"DEO starts...\")\n",
    "\n",
    "                best_particle_DEO, conv_DEO = DEO_SA(init_population=population.copy(), pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, dimension=dimension, allow_SA=False)            \n",
    "                \n",
    "                # print(\"DEOSA starts...\")\n",
    "                best_particle_DEOSA, conv_DEOSA = DEO_SA(init_population=population.copy(), pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, dimension=dimension, allow_SA=True)                                                    \n",
    "\n",
    "                conv_plot_all[\"DEO_pop_\" + str(particle_count) + \"_iter_\" + str(max_iter)] = conv_DEO\n",
    "                conv_plot_all[\"DEOSA_pop_\" + str(particle_count)+ \"_iter_\" + str(max_iter)] = conv_DEOSA                        \n",
    "\n",
    "                accuracy_DEO = compute_accuracy(train_X, train_Y, test_X, test_Y, best_particle_DEO) * 100\n",
    "                accuracy_DEOSA = compute_accuracy(train_X, train_Y, test_X, test_Y, best_particle_DEOSA) * 100\n",
    "\n",
    "                num_features_DEO = onecount(best_particle_DEO)\n",
    "                num_features_DEOSA = onecount(best_particle_DEOSA)\n",
    "\n",
    "                accuracy_DEO_runs.append(accuracy_DEO)\n",
    "                accuracy_DEOSA_runs.append(accuracy_DEOSA)\n",
    "                \n",
    "                if(accuracy_DEO > best_accuracy_DEO):\n",
    "                    best_accuracy_DEO = accuracy_DEO.copy()\n",
    "                    best_num_features_DEO = np.float64(num_features_DEO).copy()\n",
    "                    \n",
    "                if(accuracy_DEOSA > best_accuracy_DEOSA):\n",
    "                    best_accuracy_DEOSA = accuracy_DEOSA.copy()\n",
    "                    best_num_features_DEOSA = np.float64(num_features_DEOSA).copy()\n",
    "\n",
    "                avg_accuracy_DEO += accuracy_DEO\n",
    "                avg_num_features_DEO += np.float64(num_features_DEO).copy()\n",
    "\n",
    "                avg_accuracy_DEOSA += accuracy_DEOSA\n",
    "                avg_num_features_DEOSA += np.float64(num_features_DEOSA).copy()\n",
    "\n",
    "\n",
    "            std_deviation_accuracy_DEO = np.std(accuracy_DEO_runs)\n",
    "            std_deviation_accuracy_DEOSA = np.std(accuracy_DEOSA_runs)\n",
    "\n",
    "            std_deviation_accuracy_DEO = np.std(accuracy_DEO_runs)\n",
    "            std_deviation_accuracy_DEOSA = np.std(accuracy_DEOSA_runs)\n",
    "\n",
    "            avg_accuracy_DEO /= max_runs\n",
    "            avg_num_features_DEO /= max_runs\n",
    "\n",
    "            avg_accuracy_DEOSA /= max_runs\n",
    "            avg_num_features_DEOSA /= max_runs\n",
    "           \n",
    "            if(best_accuracy_DEOSA > best_accuracy):\n",
    "                best_pop = particle_count\n",
    "                best_iter = max_iter                \n",
    "\n",
    "            final_result[DEO_key + \"best_accuracy\"] = best_accuracy_DEO\n",
    "            final_result[DEOSA_key + \"best_accuracy\"] = best_accuracy_DEOSA\n",
    "            final_result[DEO_key + \"avg_accuracy\"] = avg_accuracy_DEO\n",
    "            final_result[DEOSA_key + \"avg_accuracy\"] = avg_accuracy_DEOSA\n",
    "\n",
    "            final_result[DEO_key + \"best_num_features\"] = best_num_features_DEO\n",
    "            final_result[DEOSA_key + \"best_num_features\"] = best_num_features_DEOSA\n",
    "            final_result[DEO_key + \"avg_num_features\"] = avg_num_features_DEO\n",
    "            final_result[DEOSA_key + \"avg_num_features\"] = avg_num_features_DEOSA\n",
    "\n",
    "            print('\\n=================================================')\n",
    "            print('     Results for (Pop - {}, Iter - {})'.format(particle_count, max_iter))\n",
    "            print('=================================================')\n",
    "            print('DEO best:', best_accuracy_DEO)\n",
    "            print('DEO average:', avg_accuracy_DEO)\n",
    "            print('DEO std:', std_deviation_accuracy_DEO)\n",
    "            print('')\n",
    "            print('DEOSA best:', best_accuracy_DEOSA)     \n",
    "            print('DEOSA average:', avg_accuracy_DEOSA)  \n",
    "            print('DEOSA std:', std_deviation_accuracy_DEOSA)   \n",
    "            print('=================================================\\n')\n",
    "\n",
    "    # print(\"Best combination:\" + \" Pop - \" + str(best_pop) + \" Iter - \" + str(best_iter))\n",
    "    conv_plot[\"DEO\"] = conv_plot_all[\"DEO_pop_\" + str(best_pop) + \"_iter_\" + str(max_iter)]\n",
    "    conv_plot[\"DEOSA\"] = conv_plot_all[\"DEOSA_pop_\" + str(best_pop) + \"_iter_\" + str(max_iter)]\n",
    "        \n",
    "    return final_result, conv_plot    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the global parameters and run the following cell to perform feature selection over UCI datasets\n",
    "\n",
    "* This code will automatically create two excel files - one for parameter variation and another one for convergence. The results will be saved as parameter_variation and convergence in Results folder\n",
    "\n",
    "* It will also plot convergence curves which will be saved in Convergence folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "===============================================================================\n",
      "Dataset: BreastCancer\n",
      "dimension: 10\n",
      "Total Acc:  60.71428571428571\n",
      "\n",
      "===============================================================================\n",
      "Dataset: BreastEW\n",
      "dimension: 30\n",
      "Total Acc:  91.22807017543859\n",
      "\n",
      "===============================================================================\n",
      "Dataset: CongressEW\n",
      "dimension: 16\n",
      "Total Acc:  91.95402298850574\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Exactly\n",
      "dimension: 13\n",
      "Total Acc:  76.5\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Exactly2\n",
      "dimension: 13\n",
      "Total Acc:  69.0\n",
      "\n",
      "===============================================================================\n",
      "Dataset: HeartEW\n",
      "dimension: 13\n",
      "Total Acc:  74.07407407407408\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Ionosphere\n",
      "dimension: 34\n",
      "Total Acc:  88.57142857142857\n",
      "\n",
      "===============================================================================\n",
      "Dataset: KrVsKpEW\n",
      "dimension: 36\n",
      "Total Acc:  96.08763693270735\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Lymphography\n",
      "dimension: 18\n",
      "Total Acc:  73.33333333333333\n",
      "\n",
      "===============================================================================\n",
      "Dataset: M-of-n\n",
      "dimension: 13\n",
      "Total Acc:  88.5\n",
      "\n",
      "===============================================================================\n",
      "Dataset: PenglungEW\n",
      "dimension: 325\n",
      "Total Acc:  93.33333333333333\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Sonar\n",
      "dimension: 60\n",
      "Total Acc:  88.09523809523809\n",
      "\n",
      "===============================================================================\n",
      "Dataset: SpectEW\n",
      "dimension: 22\n",
      "Total Acc:  75.92592592592592\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Tic-tac-toe\n",
      "dimension: 9\n",
      "Total Acc:  84.89583333333334\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Vote\n",
      "dimension: 16\n",
      "Total Acc:  90.0\n",
      "\n",
      "===============================================================================\n",
      "Dataset: WaveformEW\n",
      "dimension: 40\n",
      "Total Acc:  79.7\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Wine\n",
      "dimension: 13\n",
      "Total Acc:  63.888888888888886\n",
      "\n",
      "===============================================================================\n",
      "Dataset: Zoo\n",
      "dimension: 16\n",
      "Total Acc:  85.0\n"
     ]
    }
   ],
   "source": [
    "# set the global parameters over here\n",
    "datasets=[\"BreastCancer\",\"BreastEW\",\"CongressEW\",\"Exactly\",\"Exactly2\",\"HeartEW\",\"Ionosphere\",\"KrVsKpEW\",\"Lymphography\",\"M-of-n\",\"PenglungEW\",\"Sonar\",\"SpectEW\",\"Tic-tac-toe\",\"Vote\",\"WaveformEW\",\"Wine\",\"Zoo\"]\n",
    "# datasets=[\"WaveformEW\",\"Wine\",\"Zoo\"]\n",
    "# datasets=[\"BreastEW\"]\n",
    "particle_count_testing = [50]\n",
    "max_iter_testing = [30]\n",
    "max_runs = 10\n",
    "omega = 0.9           \n",
    "a2 = 1\n",
    "a1 = 2\n",
    "GP = 0.5\n",
    "pool_size = 4\n",
    "compute_fitness = fitness_FS\n",
    "\n",
    "# initializing the excel files\n",
    "save_excel(particle_count_testing, max_iter_testing, init=1, save_type=\"parameter variation\")\n",
    "save_excel(particle_count_testing, max_iter_testing, init=1, save_type=\"convergence\")\n",
    "\n",
    "# start iterating over the datasets\n",
    "for dataset in datasets:\n",
    "    \n",
    "    # reading dataset\n",
    "    print('\\n===============================================================================')\n",
    "    print(\"Dataset:\", dataset)\n",
    "    df=pd.read_csv(\"Data/\"+dataset+\".csv\")\n",
    "    (a,b)=np.shape(df)\n",
    "    data = df.values[:,0:b-1]\n",
    "    label = df.values[:,b-1]\n",
    "    dimension = np.shape(data)[1] #particle dimension   \n",
    "    print(\"dimension:\", dimension)\n",
    "\n",
    "    # loading_dataset\n",
    "    cross = 5\n",
    "    test_size = (1/cross)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(data, label,stratify=label ,test_size=test_size)\n",
    "\n",
    "    final_result, conv_plot = DEO_driver(dataset)\n",
    "    # plot_graph(final_result, conv_plot, dataset)\n",
    "\n",
    "    save_excel(particle_count_testing, max_iter_testing, conv_plot, final_result, dataset, save_type=\"parameter variation\")\n",
    "    save_excel(particle_count_testing, max_iter_testing, conv_plot, final_result, dataset, save_type=\"convergence\")\n",
    "    print('===============================================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell for solving knapsack problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Knapsack/ks_8a.txt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e8d9e6f41e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Knapsack/ks_8a.txt'"
     ]
    }
   ],
   "source": [
    "file_path = 'Data/Knapsack/'\n",
    "file_names = [\"ks_8a\", \"ks_8b\", \"ks_8c\", \"ks_8d\", \"ks_8e\", \"ks_12a\", \"ks_12b\", \"ks_12c\", \"ks_12d\", \"ks_12e\", \"ks_16a\", \"ks_16b\", \"ks_16c\", \"ks_16d\", \"ks_16e\", \"ks_20a\", \"ks_20b\", \"ks_20c\", \"ks_20d\", \"ks_20e\", \"ks_24a\", \"ks_24b\", \"ks_24c\", \"ks_24d\", \"ks_24e\"]\n",
    "\n",
    "# set the global parameters\n",
    "omega = 0.9                 \n",
    "a2 = 1\n",
    "a1 = 2\n",
    "GP = 0.5\n",
    "max_runs = 30\n",
    "particle_count = 20\n",
    "dimension = -1\n",
    "max_iter = 500\n",
    "pool_size = 30\n",
    "fitness = fitness_Knapsack\n",
    "\n",
    "weights = []\n",
    "worth = []\n",
    "max_weight = -1\n",
    "\n",
    "for file_name in file_names:    \n",
    "    fname = file_path + file_name + \".txt\"     \n",
    "    x = open(fname, 'r')\n",
    "    count = int(x.readline())\n",
    "    \n",
    "    weights = np.array(list(map(int, x.readline().split())))\n",
    "    worth = np.array(list(map(int, x.readline().split())))\n",
    "    max_weight = int(x.readline())\n",
    "\n",
    "    dimension = count\n",
    "    \n",
    "    population = initialize(particle_count, dimension)\n",
    "    fitness_list = fitness(population)\n",
    "\n",
    "    sorted_idx = np.argsort(fitness_list)\n",
    "    population = population[sorted_idx, :].reshape((particle_count, dimension))\n",
    "    fitness_list = fitness_list[0, sorted_idx]\n",
    "\n",
    "    best_particle_BEO = np.zeros((max_runs, dimension))\n",
    "    best_particle_BEOSA = np.zeros((max_runs, dimension))\n",
    "    \n",
    "    conv_BEO = np.zeros((max_runs, max_iter))\n",
    "    conv_BEOSA = np.zeros((max_runs, max_iter))\n",
    "    \n",
    "    best_fitness_BEO = np.zeros((1, max_runs))\n",
    "    best_fitness_BEOSA = np.zeros((1, max_runs))\n",
    "\n",
    "    for run_no in range(max_runs):    \n",
    "        best_particle_BEO[run_no,:], conv_BEO[run_no,:] = EO_SA(init_population=population, dimension=dimension, pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, allow_SA=False)\n",
    "        best_particle_BEOSA[run_no,:], conv_BEOSA[run_no,:] = EO_SA(init_population=population, dimension=dimension, pool_size=pool_size, max_iter=max_iter, particle_count=particle_count, allow_SA=True)\n",
    "    \n",
    "    best_fitness_BEO[0, :] = fitness(best_particle_BEO)\n",
    "    best_fitness_BEOSA[0, :] = fitness(best_particle_BEOSA)\n",
    "    \n",
    "    print(-np.mean(best_fitness_BEO), np.std(best_fitness_BEO), -np.mean(best_fitness_BEOSA), np.std(best_fitness_BEOSA))\n",
    "    \n",
    "#     print(\"Dataset:%s  Mean:%f  Std:%f\" %(file_name, -np.mean(best_fitness), np.std(best_fitness)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}